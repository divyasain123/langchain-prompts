{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFZciC7jm78-",
        "outputId": "bdb71b20-812b-4784-f181-c56c1c331ac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "     ---------------------------------------- 50.2/50.2 kB 2.7 MB/s eta 0:00:00\n",
            "Downloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install google-play-scraper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "42-qifgEuLoN",
        "outputId": "06b9b6fc-ddef-4fca-c3c3-16b41450d236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-1.2.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.2.7 (from langchain)\n",
            "  Downloading langchain_core-1.2.7-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.7 (from langchain)\n",
            "  Downloading langgraph-1.0.7-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "     ---------------------------------------- 90.6/90.6 kB 2.6 MB/s eta 0:00:00\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
            "  Downloading sqlalchemy-2.0.46-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting PyYAML<7.0.0,>=5.3.0 (from langchain-community)\n",
            "  Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl.metadata (2.4 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
            "  Downloading aiohttp-3.13.3-cp310-cp310-win_amd64.whl.metadata (8.4 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-community)\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
            "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langsmith<1.0.0,>=0.1.125 (from langchain-community)\n",
            "  Downloading langsmith-0.6.7-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting numpy>=1.26.2 (from langchain-community)\n",
            "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
            "     ---------------------------------------- 60.8/60.8 kB 1.6 MB/s eta 0:00:00\n",
            "Collecting openai<3.0.0,>=1.109.1 (from langchain-openai)\n",
            "  Downloading openai-2.16.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
            "  Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl.metadata (21 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading multidict-6.7.1-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl.metadata (77 kB)\n",
            "     ---------------------------------------- 77.6/77.6 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.2.7->langchain)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting packaging<26.0.0,>=23.2.0 (from langchain-core<2.0.0,>=1.2.7->langchain)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core<2.0.0,>=1.2.7->langchain)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.7->langchain)\n",
            "  Downloading uuid_utils-0.14.0-cp39-abi3-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading langgraph_sdk-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading xxhash-3.6.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
            "  Downloading orjson-3.11.6-cp310-cp310-win_amd64.whl.metadata (43 kB)\n",
            "     ---------------------------------------- 43.1/43.1 kB 2.1 MB/s eta 0:00:00\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
            "  Downloading zstandard-0.25.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.10.0 (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Downloading jiter-0.12.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
            "Collecting sniffio (from openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\divya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl.metadata (7.4 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
            "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\divya\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\divya\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\divya\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\divya\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2023.7.22)\n",
            "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community)\n",
            "  Downloading greenlet-3.3.1-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\divya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai)\n",
            "  Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading ormsgpack-1.12.2-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\divya\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.5)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-1.2.7-py3-none-any.whl (108 kB)\n",
            "   ---------------------------------------- 108.8/108.8 kB 6.2 MB/s eta 0:00:00\n",
            "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "   ---------------------------------------- 84.8/84.8 kB 5.0 MB/s eta 0:00:00\n",
            "Downloading aiohttp-3.13.3-cp310-cp310-win_amd64.whl (456 kB)\n",
            "   ---------------------------------------- 456.7/456.7 kB 7.1 MB/s eta 0:00:00\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "   ---------------------------------------- 1.0/1.0 MB 11.0 MB/s eta 0:00:00\n",
            "Downloading langchain_core-1.2.7-py3-none-any.whl (490 kB)\n",
            "   ---------------------------------------- 490.2/490.2 kB 7.7 MB/s eta 0:00:00\n",
            "Downloading langgraph-1.0.7-py3-none-any.whl (157 kB)\n",
            "   ---------------------------------------- 157.4/157.4 kB 9.2 MB/s eta 0:00:00\n",
            "Downloading langsmith-0.6.7-py3-none-any.whl (309 kB)\n",
            "   ---------------------------------------- 309.4/309.4 kB 6.5 MB/s eta 0:00:00\n",
            "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
            "   ---------------------------------------- 12.9/12.9 MB 5.1 MB/s eta 0:00:00\n",
            "Downloading openai-2.16.0-py3-none-any.whl (1.1 MB)\n",
            "   ---------------------------------------- 1.1/1.1 MB 2.5 MB/s eta 0:00:00\n",
            "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "   ---------------------------------------- 463.6/463.6 kB 1.3 MB/s eta 0:00:00\n",
            "Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl (2.0 MB)\n",
            "   ---------------------------------------- 2.0/2.0 MB 6.8 MB/s eta 0:00:00\n",
            "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
            "Downloading pyyaml-6.0.3-cp310-cp310-win_amd64.whl (158 kB)\n",
            "   ---------------------------------------- 158.6/158.6 kB 3.2 MB/s eta 0:00:00\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading sqlalchemy-2.0.46-cp310-cp310-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 2.1/2.1 MB 10.5 MB/s eta 0:00:00\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl (879 kB)\n",
            "   ---------------------------------------- 879.4/879.4 kB 9.2 MB/s eta 0:00:00\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
            "   ---------------------------------------- 113.6/113.6 kB 2.2 MB/s eta 0:00:00\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl (43 kB)\n",
            "   ---------------------------------------- 43.8/43.8 kB 2.2 MB/s eta 0:00:00\n",
            "Downloading greenlet-3.3.1-cp310-cp310-win_amd64.whl (226 kB)\n",
            "   --------------------------------------- 226.1/226.1 kB 14.4 MB/s eta 0:00:00\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading jiter-0.12.0-cp310-cp310-win_amd64.whl (204 kB)\n",
            "   ---------------------------------------- 204.8/204.8 kB 6.1 MB/s eta 0:00:00\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
            "   ---------------------------------------- 46.3/46.3 kB 2.3 MB/s eta 0:00:00\n",
            "Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
            "Downloading langgraph_sdk-0.3.3-py3-none-any.whl (67 kB)\n",
            "   ---------------------------------------- 67.0/67.0 kB 901.3 kB/s eta 0:00:00\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "   ---------------------------------------- 51.0/51.0 kB 1.3 MB/s eta 0:00:00\n",
            "Downloading multidict-6.7.1-cp310-cp310-win_amd64.whl (46 kB)\n",
            "   ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
            "Downloading orjson-3.11.6-cp310-cp310-win_amd64.whl (136 kB)\n",
            "   ---------------------------------------- 136.8/136.8 kB 7.9 MB/s eta 0:00:00\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl (41 kB)\n",
            "   ---------------------------------------- 41.6/41.6 kB 981.2 kB/s eta 0:00:00\n",
            "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading uuid_utils-0.14.0-cp39-abi3-win_amd64.whl (182 kB)\n",
            "   ---------------------------------------- 182.6/182.6 kB 5.4 MB/s eta 0:00:00\n",
            "Downloading xxhash-3.6.0-cp310-cp310-win_amd64.whl (31 kB)\n",
            "Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl (86 kB)\n",
            "   ---------------------------------------- 86.9/86.9 kB 4.8 MB/s eta 0:00:00\n",
            "Downloading zstandard-0.25.0-cp310-cp310-win_amd64.whl (506 kB)\n",
            "   ---------------------------------------- 506.1/506.1 kB 8.0 MB/s eta 0:00:00\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading ormsgpack-1.12.2-cp310-cp310-win_amd64.whl (117 kB)\n",
            "   ---------------------------------------- 117.2/117.2 kB 6.7 MB/s eta 0:00:00\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: zstandard, xxhash, uuid-utils, typing-extensions, tenacity, sniffio, requests, PyYAML, python-dotenv, propcache, packaging, ormsgpack, orjson, numpy, mypy-extensions, jsonpointer, jiter, httpx-sse, h11, greenlet, frozenlist, distro, attrs, async-timeout, annotated-types, aiohappyeyeballs, typing-inspection, typing-inspect, tiktoken, SQLAlchemy, requests-toolbelt, pydantic-core, multidict, marshmallow, jsonpatch, httpcore, exceptiongroup, aiosignal, yarl, pydantic, dataclasses-json, anyio, pydantic-settings, httpx, aiohttp, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph-prebuilt, langchain-classic, langgraph, langchain-community, langchain\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "Successfully installed PyYAML-6.0.3 SQLAlchemy-2.0.46 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.12.1 async-timeout-4.0.3 attrs-25.4.0 dataclasses-json-0.6.7 distro-1.9.0 exceptiongroup-1.3.1 frozenlist-1.8.0 greenlet-3.3.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 jiter-0.12.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.2.7 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-core-1.2.7 langchain-openai-1.1.7 langchain-text-splitters-1.1.0 langgraph-1.0.7 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.7 langgraph-sdk-0.3.3 langsmith-0.6.7 marshmallow-3.26.2 multidict-6.7.1 mypy-extensions-1.1.0 numpy-2.2.6 openai-2.16.0 orjson-3.11.6 ormsgpack-1.12.2 packaging-25.0 propcache-0.4.1 pydantic-2.12.5 pydantic-core-2.41.5 pydantic-settings-2.12.0 python-dotenv-1.2.1 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.12.0 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.2 uuid-utils-0.14.0 xxhash-3.6.0 yarl-1.22.0 zstandard-0.25.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\DIVYA\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~umpy'.\n",
            "  You can safely remove it manually.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.2.6 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 26.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain langchain-community langchain-openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RvB0x4XCuPWh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "os.environ[\"OPENAI_API_BASE\"] = \"https://openrouter.ai/api/v1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IuHTnuKbnD4H",
        "outputId": "ee25b341-c8ad-42d1-efdc-8d1641dcf8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Date: 2026-01-22 00:19:39\n",
            "Rating: 5\n",
            "Review: on time delivery, thank you Zomato\n",
            "----------\n",
            "Date: 2026-01-22 00:15:50\n",
            "Rating: 4\n",
            "Review: excellent\n",
            "----------\n",
            "Date: 2026-01-22 00:10:59\n",
            "Rating: 1\n",
            "Review: bakwash hai no refund no product test\n",
            "----------\n",
            "Date: 2026-01-22 00:10:46\n",
            "Rating: 5\n",
            "Review: good experience\n",
            "----------\n",
            "Date: 2026-01-22 00:03:55\n",
            "Rating: 5\n",
            "Review: good service neet\n",
            "----------\n",
            "Date: 2026-01-21 23:56:56\n",
            "Rating: 5\n",
            "Review: nice\n",
            "----------\n",
            "Date: 2026-01-21 23:50:11\n",
            "Rating: 5\n",
            "Review: amazing experience\n",
            "----------\n",
            "Date: 2026-01-21 23:47:20\n",
            "Rating: 5\n",
            "Review: good\n",
            "----------\n",
            "Date: 2026-01-21 23:45:36\n",
            "Rating: 5\n",
            "Review: always help me to fulfil my craving.\n",
            "----------\n",
            "Date: 2026-01-21 23:38:23\n",
            "Rating: 5\n",
            "Review: wooooo\n",
            "----------\n",
            "Date: 2026-01-21 23:34:55\n",
            "Rating: 5\n",
            "Review: very nice\n",
            "----------\n",
            "Date: 2026-01-21 23:34:47\n",
            "Rating: 5\n",
            "Review: ok\n",
            "----------\n",
            "Date: 2026-01-21 23:32:39\n",
            "Rating: 5\n",
            "Review: give me best offer for me\n",
            "----------\n",
            "Date: 2026-01-21 23:27:22\n",
            "Rating: 1\n",
            "Review: it's a fraud application, zero customer support. maha ghatiya service hai . deleting this app for forever.\n",
            "----------\n",
            "Date: 2026-01-21 23:26:54\n",
            "Rating: 5\n",
            "Review: nice aap\n",
            "----------\n",
            "Date: 2026-01-21 23:20:40\n",
            "Rating: 5\n",
            "Review: This app is help full for all person take rest in home and enjoy the food.ðŸ¥³\n",
            "----------\n",
            "Date: 2026-01-21 23:20:17\n",
            "Rating: 5\n",
            "Review: It's very easy to use and is also available at nights\n",
            "----------\n",
            "Date: 2026-01-21 23:16:17\n",
            "Rating: 1\n",
            "Review: They charge you more if you have zomato money.....please dont have any money on zomato money....absolutely hopeless..\n",
            "----------\n",
            "Date: 2026-01-21 23:15:24\n",
            "Rating: 5\n",
            "Review: good ðŸ‘\n",
            "----------\n",
            "Date: 2026-01-21 23:14:37\n",
            "Rating: 4\n",
            "Review: nice\n",
            "----------\n",
            "Date: 2026-01-21 23:08:47\n",
            "Rating: 2\n",
            "Review: Hi Zomato I've been using Zomato for 2 to 3 years. I really had the best experience with your app, features, communication and others. I gave it a 5 rating too. But, today I'm giving 2 ratings because of the price difference, As I have a premium membership. money should be lower, but my friend has no premium membership, why does he have lower than mine. My friend and I were at the same location to order food, where I got this problem. Please, check your price difference. Thank you\n",
            "----------\n",
            "Date: 2026-01-21 23:07:04\n",
            "Rating: 5\n",
            "Review: Good food at affordable prices for lazy chefs like me ðŸ˜\n",
            "----------\n",
            "Date: 2026-01-21 23:04:11\n",
            "Rating: 5\n",
            "Review: good health\n",
            "----------\n",
            "Date: 2026-01-21 23:01:14\n",
            "Rating: 5\n",
            "Review: Too Good\n",
            "----------\n",
            "Date: 2026-01-21 23:01:13\n",
            "Rating: 5\n",
            "Review: ðŸ‘\n",
            "----------\n",
            "Date: 2026-01-21 22:59:25\n",
            "Rating: 4\n",
            "Review: very nice ðŸ‘\n",
            "----------\n",
            "Date: 2026-01-21 22:57:30\n",
            "Rating: 5\n",
            "Review: wonderfull\n",
            "----------\n",
            "Date: 2026-01-21 22:56:33\n",
            "Rating: 5\n",
            "Review: nice\n",
            "----------\n",
            "Date: 2026-01-21 22:56:24\n",
            "Rating: 5\n",
            "Review: Amazing food + superb service! Staff was very cooperative. Highly recommended ðŸ‘ Special thanks to Amit.\n",
            "----------\n",
            "Date: 2026-01-21 22:54:27\n",
            "Rating: 1\n",
            "Review: the aap is best but your team is very slow about assigning delivery partner and the app is very bad about applying offer and coupons etc. ðŸ˜ðŸ˜’\n",
            "----------\n",
            "Date: 2026-01-21 22:54:24\n",
            "Rating: 4\n",
            "Review: good service\n",
            "----------\n",
            "Date: 2026-01-21 22:53:04\n",
            "Rating: 5\n",
            "Review: GOOD\n",
            "----------\n",
            "Date: 2026-01-21 22:52:27\n",
            "Rating: 5\n",
            "Review: best experience in zomato\n",
            "----------\n",
            "Date: 2026-01-21 22:51:55\n",
            "Rating: 5\n",
            "Review: very good\n",
            "----------\n",
            "Date: 2026-01-21 22:51:01\n",
            "Rating: 5\n",
            "Review: goog\n",
            "----------\n",
            "Date: 2026-01-21 22:46:24\n",
            "Rating: 5\n",
            "Review: gud\n",
            "----------\n",
            "Date: 2026-01-21 22:44:38\n",
            "Rating: 5\n",
            "Review: Too good ðŸ‘ðŸ»\n",
            "----------\n",
            "Date: 2026-01-21 22:44:09\n",
            "Rating: 5\n",
            "Review: very nice experience with zomato\n",
            "----------\n",
            "Date: 2026-01-21 22:43:31\n",
            "Rating: 5\n",
            "Review: nice\n",
            "----------\n",
            "Date: 2026-01-21 22:41:30\n",
            "Rating: 3\n",
            "Review: Good\n",
            "----------\n",
            "Date: 2026-01-21 22:39:59\n",
            "Rating: 5\n",
            "Review: ðŸ˜²\n",
            "----------\n",
            "Date: 2026-01-21 22:39:44\n",
            "Rating: 5\n",
            "Review: super\n",
            "----------\n",
            "Date: 2026-01-21 22:35:59\n",
            "Rating: 5\n",
            "Review: very nice\n",
            "----------\n",
            "Date: 2026-01-21 22:35:50\n",
            "Rating: 1\n",
            "Review: worst app maina food order Kiya tha food ek dam bekar tha jab maina compliant kiya toh bina koi update diya conversation ko end kar diya gaya without my consent worst coustomer service\n",
            "----------\n",
            "Date: 2026-01-21 22:35:30\n",
            "Rating: 1\n",
            "Review: Sabse bekaar app delivery bekaar hai iski paise ke Zomato wale. Chor app\n",
            "----------\n",
            "Date: 2026-01-21 22:34:57\n",
            "Rating: 5\n",
            "Review: ðŸ¥°ðŸ™ðŸ»ðŸ™ðŸ»ðŸ™ðŸ»ðŸ™ðŸ»\n",
            "----------\n",
            "Date: 2026-01-21 22:33:00\n",
            "Rating: 5\n",
            "Review: im eating so reviewing in one hand\n",
            "----------\n",
            "Date: 2026-01-21 22:30:38\n",
            "Rating: 5\n",
            "Review: good service ðŸ‘\n",
            "----------\n",
            "Date: 2026-01-21 22:27:37\n",
            "Rating: 4\n",
            "Review: good service\n",
            "----------\n",
            "Date: 2026-01-21 22:25:37\n",
            "Rating: 5\n",
            "Review: good ðŸ‘\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "from google_play_scraper import reviews, Sort\n",
        "\n",
        "APP_ID = \"com.application.zomato\"\n",
        "\n",
        "result, _ = reviews(\n",
        "    APP_ID,\n",
        "    lang='en',\n",
        "    country='in',\n",
        "    sort=Sort.NEWEST,\n",
        "    count=50\n",
        ")\n",
        "\n",
        "for r in result:\n",
        "    print(\"Date:\", r[\"at\"])\n",
        "    print(\"Rating:\", r[\"score\"])\n",
        "    print(\"Review:\", r[\"content\"])\n",
        "    print(\"-\" * 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "NRmhZdVnnRUn",
        "outputId": "318542a5-1375-4fbf-9d59-e349ced605fe"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(result)\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[0;32m      3\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "df=pd.DataFrame(result)\n",
        "df['date'] = df['at'].dt.date\n",
        "df[['date', 'score', 'content']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WSWk1s7M7SXd"
      },
      "outputs": [],
      "source": [
        "base_path = \"data/zomato\"\n",
        "os.makedirs(base_path, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "KmMIh83A7o0E"
      },
      "outputs": [],
      "source": [
        "for date, daily_df in df.groupby('date'):\n",
        "    file_path = f\"{base_path}/{date}.csv\"\n",
        "    daily_df[['date', 'score', 'content']].to_csv(file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "1fKzVsNwsVq2"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=128\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zucRp4BhMS_z",
        "outputId": "1cc2a772-1d9c-480f-a2a5-4c5f76ab3c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "excellent\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/data/zomato/2026-01-08.csv\")\n",
        "\n",
        "sample_review = df.iloc[0][\"content\"]\n",
        "\n",
        "print(sample_review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "DqDYYu2sAebW"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(template=\"\"\"\n",
        "You are analyzing Google Play Store app reviews.\n",
        "\n",
        "Your task is to extract ALL concrete topics related to:\n",
        "- specific issues\n",
        "- specific complaints\n",
        "- specific requests\n",
        "- specific suggestions\n",
        "- specific feedback about features, service, or experience\n",
        "\n",
        "CRITICAL RULES:\n",
        "- Topics MUST refer to a concrete aspect (delivery, food, app, support, pricing, etc.)\n",
        "- Do NOT return generic phrases like:\n",
        "  \"Positive feedback\", \"Negative feedback\", \"Good experience\", \"Bad experience\"\n",
        "- Do NOT summarize sentiment\n",
        "- Topics must be short, specific phrases (3â€“6 words)\n",
        "- Always extract at least one concrete topic\n",
        "- Multiple topics are allowed\n",
        "\n",
        "Review:\n",
        "{review}\n",
        "\n",
        "Return topics as a bullet list.\n",
        "\"\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2-My3NisJNR",
        "outputId": "c4418b6a-173a-468f-a4ce-6627dc0bc786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- No specific topics identified\n"
          ]
        }
      ],
      "source": [
        "chain=prompt | model | StrOutputParser()\n",
        "\n",
        "response = chain.invoke({\n",
        "    \"review\": sample_review\n",
        "})\n",
        "\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "3c-XbRkWMt4U"
      },
      "outputs": [],
      "source": [
        "canonical_topics = set([\n",
        "    \"Delivery issue\",\n",
        "    \"Delivery partner rude\",\n",
        "    \"Late delivery\",\n",
        "    \"Food quality issue\",\n",
        "    \"App performance issue\",\n",
        "    \"App user interface\"\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "wxeo44vYWulW"
      },
      "outputs": [],
      "source": [
        "canonical_prompt = PromptTemplate(template=\"\"\"\n",
        "You are a topic canonicalization agent for app review analysis.\n",
        "\n",
        "Your task:\n",
        "Given a newly extracted topic and a list of existing canonical topics,\n",
        "decide the BEST canonical topic.\n",
        "\n",
        "Rules:\n",
        "- Merge aggressively\n",
        "- If the new topic is even loosely similar to an existing topic, MERGE\n",
        "- Prefer existing topics over creating new ones\n",
        "- Canonical topics must be short, neutral, and stable over time\n",
        "- Avoid synonyms, paraphrases, or stylistic variations\n",
        "\n",
        "If merging:\n",
        "- Return the EXACT existing topic name\n",
        "\n",
        "If creating a new topic:\n",
        "- Rewrite it into a clean, neutral canonical form\n",
        "\n",
        "Inputs:\n",
        "New topic:\n",
        "{new_topic}\n",
        "\n",
        "Existing canonical topics:\n",
        "{existing_topics}\n",
        "\n",
        "Return ONLY ONE topic name. No explanation.\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "7Ob-G_6wXRka"
      },
      "outputs": [],
      "source": [
        "canonical_chain = canonical_prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pcfxHRKYaf_"
      },
      "source": [
        "testing with real eg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYYYkoYVXusP",
        "outputId": "6c9c3cb1-707a-445c-a14e-bbff5559b0fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "App performance issue\n"
          ]
        }
      ],
      "source": [
        "existing = list(canonical_topics)\n",
        "\n",
        "response = canonical_chain.invoke({\n",
        "    \"new_topic\": \"Smooth performance\",\n",
        "    \"existing_topics\": existing\n",
        "})\n",
        "\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZUbuTRIX3s1",
        "outputId": "6813a03b-5266-458b-826e-b9211ec13273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "App user interface\n"
          ]
        }
      ],
      "source": [
        "response = canonical_chain.invoke({\n",
        "    \"new_topic\": \"UI design\",\n",
        "    \"existing_topics\": existing\n",
        "})\n",
        "\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGR1QhNqX-eB",
        "outputId": "08ea2ed6-2add-4885-98a9-04d858612a37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Refund not received\n"
          ]
        }
      ],
      "source": [
        "response = canonical_chain.invoke({\n",
        "    \"new_topic\": \"Refund not received\",\n",
        "    \"existing_topics\": existing\n",
        "})\n",
        "\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Wz8ImBLIYCuj"
      },
      "outputs": [],
      "source": [
        "canonical_topics.add(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ri8m48ZZCLY",
        "outputId": "90019f1e-b400-4905-9478-1caef392e50b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'App performance issue',\n",
              " 'App user interface',\n",
              " 'Delivery issue',\n",
              " 'Delivery partner rude',\n",
              " 'Food quality issue',\n",
              " 'Late delivery',\n",
              " 'Refund not received'}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "canonical_topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "r2rG2N_sakad"
      },
      "outputs": [],
      "source": [
        "topic_chain = chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bUM_rSXZTiJ",
        "outputId": "3bab0a3c-893b-4f36-edbf-42cc05f67e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: 2026-01-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing reviews: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [01:40<00:00,  2.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: 2026-01-09\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing reviews: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:46<00:00,  2.13s/it]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/data/zomato\"\n",
        "daily_topic_store = {}\n",
        "\n",
        "for file in sorted(os.listdir(data_dir)):\n",
        "    if file.endswith(\".csv\"):\n",
        "        date = file.replace(\".csv\", \"\")\n",
        "        print(\"Processing:\", date)\n",
        "\n",
        "        daily_topic_store[date] = process_daily_reviews(\n",
        "            csv_path=f\"{data_dir}/{file}\",\n",
        "            topic_chain=topic_chain,\n",
        "            canonical_chain=canonical_chain,\n",
        "            canonical_topics=canonical_topics\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8M2Nrk9NRPw",
        "outputId": "6cbca7ab-9697-4d49-a6b8-2825b3ae56c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "sP7MOyqsNdE0",
        "outputId": "7de89225-2677-41b5-a8af-837b2c03640b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"trend_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"2026-01-08\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 0,\n        \"max\": 82,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5,\n          82,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2026-01-09\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45,\n        \"min\": 0,\n        \"max\": 131,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          131,\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "trend_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-91942dee-c9fa-4d76-9022-21de86a12a96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2026-01-08</th>\n",
              "      <th>2026-01-09</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>App performance issue</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>No specific suggestions mentioned</th>\n",
              "      <td>82</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>App user interface</th>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Delivery issue</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Late delivery</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Food quality issue</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Refund not received</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Delivery partner rude</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91942dee-c9fa-4d76-9022-21de86a12a96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91942dee-c9fa-4d76-9022-21de86a12a96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91942dee-c9fa-4d76-9022-21de86a12a96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-47eddea1-67ce-49fe-924b-f9d2ffbafb72\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47eddea1-67ce-49fe-924b-f9d2ffbafb72')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-47eddea1-67ce-49fe-924b-f9d2ffbafb72 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6d0c351b-6f0b-49eb-9587-64d42c21a5e8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('trend_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6d0c351b-6f0b-49eb-9587-64d42c21a5e8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('trend_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                   2026-01-08  2026-01-09\n",
              "App performance issue                       5           4\n",
              "No specific suggestions mentioned          82         131\n",
              "App user interface                         11           8\n",
              "Delivery issue                              7           7\n",
              "Late delivery                               3           5\n",
              "Food quality issue                          7           2\n",
              "Refund not received                         1           0\n",
              "Delivery partner rude                       0           1"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trend_df = pd.DataFrame(daily_topic_store).fillna(0).astype(int)\n",
        "trend_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "m4PWqQWJZSI2"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.makedirs(\"output\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "OaEsHPo4QFKK"
      },
      "outputs": [],
      "source": [
        "output_path = \"output/zomato_topic_trend_sample.csv\"\n",
        "trend_df.to_csv(output_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EQt-Bk3QzH1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
